{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "B3QOW7VGXEXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1447, 0.1108, 0.4910],\n",
      "        [0.8418, 0.4819, 0.9591],\n",
      "        [0.5382, 0.3743, 0.5309],\n",
      "        [0.7117, 0.7145, 0.7193],\n",
      "        [0.7661, 0.6256, 0.6781]])\n"
     ]
    }
   ],
   "source": [
    "# Comprueba si tienes instalado Pytorch en tu Sistema WSl2 con ROcm:\n",
    "import torch\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "#torch.cuda.is_available()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQPQtQXfXEXS"
   },
   "source": [
    "## Trabajando con datos\n",
    "PyTorch manipula dos tipos primitivos de datos:\n",
    "``torch.utils.data.DataLoader`` and ``torch.utils.data.Dataset``.\n",
    "``Dataset`` almacena sus muestras con sus etiquetas correspondientes, y ``DataLoader`` crea una iteracion en el ``Dataset``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nZX_hIW_XEXU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a3r9-gCXEXV"
   },
   "source": [
    "PyTorch ofrece bibliotecas específicas de dominio como ``TorchText``, ``TorchVision`` y ``TorchAudio``, todas las cuales incluyen conjuntos de datos. Aqui utilizamos un conjunto de datos ``TorchVision``.\n",
    "\n",
    "El módulo torchvision.datasets contiene objetos Dataset para muchos datos de visión del mundo real como CIFAR, COCO. En este tutorial, utilizamos el conjunto de datos FashionMNIST. Cada TorchVision Dataset incluye dos argumentos: transform y target_transform para modificar las muestras y las etiquetas respectivamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m6Eb-C-gXEXV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugbhe20WXEXW"
   },
   "source": [
    "Pasamos el conjunto de datos como argumento a DataLoader. Esto envuelve un iterable sobre nuestro conjunto de datos, y soporta la carga automática de datos por lotes, muestreo, barajado y multiproceso. Aquí definimos un tamaño de lote de 64, es decir, cada elemento en el iterable dataloader devolverá un lote de 64 características y etiquetas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KWV9YUYSXEXW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M40kGa2HXEXX"
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBfG-ylwXEXX"
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZippKkuXEXY"
   },
   "source": [
    "## Creando modelos\n",
    "Para definir una red neuronal en PyTorch, creamos una clase que hereda de [nn.Module]. Definimos las capas de la red en la función __init__ y especificamos cómo pasarán los datos a través de la red en la función forward. Para acelerar las operaciones en la red neuronal, la movemos a la GPU o MPS si está disponible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WHa4XtUMXEXY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LQmHFLdXEXZ"
   },
   "source": [
    "## Optimizando los parametros del modelo\n",
    "Para entrenar un modelo, necesitamos la funcion: [loss function]\n",
    "y tambien: [optimizer]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IJ54sB-AXEXZ"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWq33TpEXEXZ"
   },
   "source": [
    "En un único bucle de entrenamiento, el modelo realiza predicciones sobre el conjunto de datos de entrenamiento (alimentado por lotes), y retropropaga el error de predicción para ajustar los parámetros del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Cf4ok8oeXEXZ"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDvSkATbXEXZ"
   },
   "source": [
    "También comprobamos el rendimiento del modelo con el conjunto de datos de prueba para asegurarnos de que está aprendiendo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1RYNgb7wXEXa"
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEMTURGJXEXa"
   },
   "source": [
    "El proceso de entrenamiento se lleva a cabo a lo largo de varias iteraciones (*epochs*). Durante cada epoch, el modelo aprende\n",
    "parámetros para hacer mejores predicciones. Imprimimos la precisión y la pérdida del modelo en cada época.\n",
    "y la pérdida disminuye con cada epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VolTd0VmXEXa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.287865  [   64/60000]\n",
      "loss: 2.280092  [ 6464/60000]\n",
      "loss: 2.256556  [12864/60000]\n",
      "loss: 2.262291  [19264/60000]\n",
      "loss: 2.234435  [25664/60000]\n",
      "loss: 2.199603  [32064/60000]\n",
      "loss: 2.211268  [38464/60000]\n",
      "loss: 2.168447  [44864/60000]\n",
      "loss: 2.174129  [51264/60000]\n",
      "loss: 2.142170  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 39.1%, Avg loss: 2.134272 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.144091  [   64/60000]\n",
      "loss: 2.134423  [ 6464/60000]\n",
      "loss: 2.075452  [12864/60000]\n",
      "loss: 2.102607  [19264/60000]\n",
      "loss: 2.026638  [25664/60000]\n",
      "loss: 1.972186  [32064/60000]\n",
      "loss: 2.004623  [38464/60000]\n",
      "loss: 1.918372  [44864/60000]\n",
      "loss: 1.931993  [51264/60000]\n",
      "loss: 1.861191  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.853627 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.891190  [   64/60000]\n",
      "loss: 1.858196  [ 6464/60000]\n",
      "loss: 1.741704  [12864/60000]\n",
      "loss: 1.789665  [19264/60000]\n",
      "loss: 1.655540  [25664/60000]\n",
      "loss: 1.626629  [32064/60000]\n",
      "loss: 1.649438  [38464/60000]\n",
      "loss: 1.552204  [44864/60000]\n",
      "loss: 1.576613  [51264/60000]\n",
      "loss: 1.482660  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 1.491036 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.564472  [   64/60000]\n",
      "loss: 1.525910  [ 6464/60000]\n",
      "loss: 1.380744  [12864/60000]\n",
      "loss: 1.453895  [19264/60000]\n",
      "loss: 1.321742  [25664/60000]\n",
      "loss: 1.337513  [32064/60000]\n",
      "loss: 1.351952  [38464/60000]\n",
      "loss: 1.280242  [44864/60000]\n",
      "loss: 1.308921  [51264/60000]\n",
      "loss: 1.226530  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.240245 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.324038  [   64/60000]\n",
      "loss: 1.298956  [ 6464/60000]\n",
      "loss: 1.140141  [12864/60000]\n",
      "loss: 1.242846  [19264/60000]\n",
      "loss: 1.109737  [25664/60000]\n",
      "loss: 1.150263  [32064/60000]\n",
      "loss: 1.172666  [38464/60000]\n",
      "loss: 1.111516  [44864/60000]\n",
      "loss: 1.143608  [51264/60000]\n",
      "loss: 1.075661  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 1.084606 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"¡Trabajo completado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyJnnus3XEXa"
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Jk2cvI3XEXa"
   },
   "source": [
    "## Guardando modelos\n",
    "Una forma común de guardar un modelo es serializar el diccionario de estado interno (que contiene los parámetros del modelo).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9SovWGsUXEXa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando el estado del modelo al archivo-> model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Guardando el estado del modelo al archivo-> model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sp7RYX4IXEXb"
   },
   "source": [
    "## Cargando modelos\n",
    "\n",
    "El proceso para cargar un modelo incluye recrear la estructura del modelo y cargar\n",
    "el diccionario de estados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8tp0S34MXEXb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ms7ZzEbkXEXb"
   },
   "source": [
    "Este modelo puede utilizarse ahora para hacer predicciones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FJfofi0oXEXb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
